{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/dcase/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytz import timezone\n",
    "from sklearn.externals import joblib\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from load_dataset import AudioDataset\n",
    "from train_coarse import VGG_alt, device  #  TEST_LOADER\n",
    "# from train_branches import VGG_alt as VGG_alt_fine, get_label_range\n",
    "\n",
    "##  edit the optimizer  'rmsprop' or 'adam' for different model test \n",
    "from train_branches_20190711_1_one_part_one_model import VGG_alt as VGG_alt_fine, get_label_range\n",
    "\n",
    "# from train_branches_20190711_2_one_part_one_model_no_dropout import VGG_alt as VGG_alt_fine, get_label_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE: 20190715_141637\n"
     ]
    }
   ],
   "source": [
    "DATE = datetime.now(timezone('US/Pacific')).strftime('%Y%m%d_%H%M%S')\n",
    "print(f'DATE: {DATE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "LINUX = True\n",
    "\n",
    "#FINE = False\n",
    "#COARSE = True\n",
    "\n",
    "COARSE_WITH_FINE_TOP_LEVEL_MODEL = True\n",
    "\n",
    "FINE_TO_COARSE_LOGIC = False\n",
    "\n",
    "VGG_EMBED = True\n",
    "L3_EMBED = False\n",
    "\n",
    "if not LINUX:\n",
    "    basepath = r\"D:\\repos\\Data-Processing\\audio\\test\"\n",
    "else:\n",
    "    basepath = '/dcase/spec_vgg/validate'                                  # Validate / compute metrics\n",
    "    #basepath = '/dcase/datasets-dcase-2019-5/audio-eval/features/spec_vgg'  # Final Eval set\n",
    "NUM_COARSE_LABELS = 8\n",
    "NUM_TOTAL_LABELS = 37\n",
    "NUM_FINE_LABELS = NUM_TOTAL_LABELS - NUM_COARSE_LABELS\n",
    "\n",
    "COARSE_PREDICT_THRESHOLD = 0.5  # what else?\n",
    "\n",
    "RESULT_CSV_COARSE_PATH = f'csvs/results-{DATE}-coarse.csv'\n",
    "RESULT_CSV_FINE_PATH_TEMPLATE = f'csvs/results-{DATE}-fine-%d.csv' \n",
    "RESULT_CSV_FINAL_PATH = f'csvs/results-{DATE}-final.csv'\n",
    "\n",
    "total_files = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4125"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LINUX:\n",
    "    COARSE_CHECKPOINT = \"models/20190605_085047_best_epoch_1_val_loss=0.2655.ckpt\"\n",
    "    FINE_CHECKPOINT_BASE = 'models'\n",
    "else:\n",
    "    #COARSE_CHECKPOINT = '/dcase/trained-models-branches/20190607_085504_0.773.ckpt'\n",
    "    #COARSE_CHECKPOINT =  '/dcase/trained-models-branches/20190610_083507_coarse=0.777_fine=0.644.ckpt'\n",
    "    #COARSE_CHECKPOINT = '/dcase/models/20190610_083507_coarse=0.777_fine=0.644.ckpt'\n",
    "    \n",
    "    #Best Coarse from Daniel:\n",
    "    COARSE_CHECKPOINT = '/dcase/models/20190610_170308_coarse=0.787_fine=0.646.ckpt'\n",
    "    \n",
    "    # Best Fine form Daniel:\n",
    "#     COARSE_CHECKPOINT = '/dcase/models/20190609_230306_coarse=0.769_fine=0.656.ckpt'\n",
    "    \n",
    "#    FINE_CHECKPOINT_BASE = '/dcase/output/models_Jianyu/one-part-1-models-logmel-best7-rmsprop-learningratechangeMuchbiggerinCallback'\n",
    "\n",
    "#     FINE_CHECKPOINT_BASE = '/dcase/output/models_Jianyu/one-part-1-models-logmel-best6-originalmodel_rmsprop-learningratechangebiggerinCallback'\n",
    "#     FINE_CHECKPOINT_BASE = '/dcase/output/models_Jianyu/one-part-1-models-logmel-best5-rmsprop-learningratechangebiggerinCallback'\n",
    "\n",
    "    FINE_CHECKPOINT_BASE = '/dcase/output/models_Jianyu/one-part-1-models-logmel-best4-rmsprop-learningratechangebiggerinCallback'\n",
    "#     FINE_CHECKPOINT_BASE = '/dcase/output/models_Jianyu/one-part-1-models-logmel-best3-rmsprop-dropoutlow'\n",
    "#     FINE_CHECKPOINT_BASE = '/dcase/output/models_Jianyu/one-part-1-models-logmel-best2-rmsp'      ## best result so far\n",
    "#     FINE_CHECKPOINT_BASE = '/dcase/output/models_Jianyu/one-part-1-models-logmel-best'\n",
    "#     FINE_CHECKPOINT_BASE = '/dcase/trained-models-branches'\n",
    "#     FINE_CHECKPOINT_BASE = '/dcase/output/models/best'\n",
    "\n",
    "FINE_CKPT_REGEX = r'.+_coarse=(\\d+)_best_.*\\.ckpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find checkpoints for fine categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumes there is at most 1 ckpt file for each coarse category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(str,\n",
       "            {5: '/dcase/output/models_Jianyu/one-part-1-models-logmel-best4-rmsprop-learningratechangebiggerinCallback/20190712_205505_coarse=5_best_epoch_3_val_loss=0.2760.ckpt',\n",
       "             4: '/dcase/output/models_Jianyu/one-part-1-models-logmel-best4-rmsprop-learningratechangebiggerinCallback/20190712_205505_coarse=4_best_epoch_9_val_loss=0.2413.ckpt',\n",
       "             0: '/dcase/output/models_Jianyu/one-part-1-models-logmel-best4-rmsprop-learningratechangebiggerinCallback/20190712_205505_coarse=0_best_epoch_5_val_loss=0.2760.ckpt',\n",
       "             3: '/dcase/output/models_Jianyu/one-part-1-models-logmel-best4-rmsprop-learningratechangebiggerinCallback/20190712_205505_coarse=3_best_epoch_17_val_loss=0.1979.ckpt',\n",
       "             6: '/dcase/output/models_Jianyu/one-part-1-models-logmel-best4-rmsprop-learningratechangebiggerinCallback/20190712_205505_coarse=6_best_epoch_11_val_loss=0.1304.ckpt',\n",
       "             1: '/dcase/output/models_Jianyu/one-part-1-models-logmel-best4-rmsprop-learningratechangebiggerinCallback/20190712_205505_coarse=1_best_epoch_3_val_loss=0.0750.ckpt'})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_paths_fine = defaultdict(str)\n",
    "for f in os.listdir(FINE_CHECKPOINT_BASE):\n",
    "    m = re.match(FINE_CKPT_REGEX, f)\n",
    "    if m:\n",
    "        coarse_idx = int(m.group(1))\n",
    "        ckpt_paths_fine[coarse_idx] = os.path.join(FINE_CHECKPOINT_BASE, f)\n",
    "ckpt_paths_fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up label names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-orders output as [fine, coarse] to match demo .csv file (maybe not necessary)\n",
    "def reorder_labels_for_submission(list_or_array):\n",
    "    if type(list_or_array) == torch.Tensor:\n",
    "        list_or_array = list(list_or_array.to('cpu').numpy())\n",
    "    list_or_array = list(list_or_array)\n",
    "    return list_or_array[8:] + list_or_array[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process label names\n",
    "label_names = joblib.load('label_order.pkl')\n",
    "label_names = [re.sub('_presence', '', label_names[i]) for i in range(len(label_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_names\n",
    "# total_files = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def make_results_csv(csv_out_path_template, model_class, ckpt_path, use_fine_model=False, coarse_idx=None,\n",
    "                    label_start=None, label_end=None, num_fine_classes=None):\n",
    "    # Skip if path to checkpoint doesn't exit (happens for single-class fine models that don't exist)\n",
    "    if not ckpt_path:\n",
    "        return\n",
    "    \n",
    "    if use_fine_model:\n",
    "        csv_out_path = csv_out_path_template % coarse_idx\n",
    "        model = model_class(num_fine_classes)\n",
    "    else:\n",
    "        # Coarse (high-level) model.\n",
    "        csv_out_path = csv_out_path_template \n",
    "        model = model_class()\n",
    "\n",
    "    # Initialize model weights from checkpoint.\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()    \n",
    "        \n",
    "    print(f'Making results file: {csv_out_path}')\n",
    "    with open(csv_out_path, 'w') as c:\n",
    "        writer = csv.writer(c, delimiter=',')\n",
    "\n",
    "        header = ['audio_filename'] + reorder_labels_for_submission(label_names)\n",
    "        writer.writerow(header)\n",
    "        data_rows = []\n",
    "        for filename in tqdm_notebook(os.listdir(basepath)):\n",
    "            # Only eval on non-augmented validation set data. TODO: remove extraneous files from validation dataset\n",
    "            if '_pitch_changes-0_volume_changes-0_background_changes-None-None' not in filename:\n",
    "                continue\n",
    "            audio_filename = filename[0:9] + '.wav'\n",
    "#             total_files = total_files + 1\n",
    "            \n",
    "            ###### load data for validation \n",
    "            ###### \n",
    "            spectrogram, vgg, label = joblib.load(os.path.join(basepath, filename))\n",
    "    #         print(spectrogram.shape, emb.shape, label.shape)\n",
    "            spectrogram = np.expand_dims(spectrogram, axis=0)\n",
    "            spectrogram = np.expand_dims(spectrogram, axis=0)\n",
    "\n",
    "    #         print(vgg.flatten().shape)\n",
    "            vgg = torch.from_numpy(vgg.flatten().reshape((1, 1280)))\n",
    "            spectrogram = spectrogram.astype(np.float32)\n",
    "            spectrogram = torch.from_numpy(spectrogram)\n",
    "    #         print(spectrogram.shape, emb.shape, label.shape)\n",
    "            in_data = (spectrogram, vgg)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                results = model(in_data)\n",
    "#                 print(\"results length1\")  # 37 \n",
    "#                 print(len(results[0]))    # 37 \n",
    "                results = torch.sigmoid(results[0])\n",
    "#                 print(\"results length2\")  # 37 \n",
    "#                 print(len(results))       # 37 \n",
    "                #print(label)\n",
    "                #print(results)\n",
    "                #print()\n",
    "                label_true = np.where(label == 1)[0]\n",
    "                label_name = [label_names[i] for i in label_true]\n",
    "    #             print(label_name)\n",
    "    #             img_array = img_array.reshape((16, 16))\n",
    "    #             plt.imshow(img_array, cmap='hot', interpolation='nearest')\n",
    "    #             plt.show()\n",
    "    #             print(results.shape)\n",
    "\n",
    "                results = results.detach().numpy()\n",
    "                if use_fine_model:\n",
    "                    print(\"use_fine_model\")\n",
    "                    if FINE_TO_COARSE_LOGIC:\n",
    "                        print(\"FINE_TO_COARSE_LOGIC is true\")\n",
    "                        coarse_labels = []\n",
    "                        fine_label_names = label_names[NUM_COARSE_LABELS:]\n",
    "                        coarse_label_dict = {i: [] for i in range(NUM_COARSE_LABELS)}\n",
    "                        for i, r in enumerate(results):\n",
    "        #                     print(fine_label_names[i][0])\n",
    "                            coarse_label_dict[int(fine_label_names[i][0])-1].append(r)\n",
    "                        for i in range(NUM_COARSE_LABELS):\n",
    "                            coarse_labels.append(max(coarse_label_dict[i]))\n",
    "        #                 print('coarse labels', coarse_labels)\n",
    "                        results = coarse_labels + list(results)\n",
    "                    else:\n",
    "                        print(\"FINE_TO_COARSE_LOGIC is false\")\n",
    "                        full_results = np.zeros(NUM_TOTAL_LABELS)\n",
    "                        full_results[label_start : label_end] = results\n",
    "                        results = full_results\n",
    "                        \n",
    "                elif COARSE_WITH_FINE_TOP_LEVEL_MODEL:\n",
    "                    results = list(results)\n",
    "                else:\n",
    "                    # Coarse model.\n",
    "                    results = list(results) + [0 for i in range(NUM_FINE_LABELS)]\n",
    "\n",
    "                results = reorder_labels_for_submission(results)\n",
    "                #print (results)\n",
    "                data_rows.append([audio_filename] + results)\n",
    "    #             print([audio_filename] + results)\n",
    "        writer.writerows(data_rows)\n",
    "    \n",
    "    # Clean up.\n",
    "    del ckpt\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_names\n",
    "from sklearn.externals import joblib\n",
    "Test_data = joblib.load('/dcase/spec_vgg/label_to_files_test.zip')\n",
    "# test[1]\n",
    "\n",
    "# print(type(Test_data[0]))\n",
    "# print(len(Test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = ['1_engine', '2_machinery-impact', '3_non-machinery-impact', '4_powered-saw', '5_alert-signal', '6_music', '7_human-voice', '8_dog']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fine_results_csv(csv_out_path_template, model_class, ckpt_path, use_fine_model=False, coarse_idx=None,\n",
    "                    label_start=None, label_end=None, num_fine_classes=None):\n",
    "    # Skip if path to checkpoint doesn't exit (happens for single-class fine models that don't exist)\n",
    "    if not ckpt_path:\n",
    "        return\n",
    "    \n",
    "    if use_fine_model:\n",
    "        csv_out_path = csv_out_path_template % coarse_idx\n",
    "        model = model_class(num_fine_classes)\n",
    "    else:\n",
    "        # Coarse (high-level) model.\n",
    "        csv_out_path = csv_out_path_template \n",
    "        model = model_class()\n",
    "\n",
    "    # Initialize model weights from checkpoint.\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "    target_annotation = annotations[coarse_idx]\n",
    "    print(coarse_idx, \"     \", target_annotation)\n",
    "        \n",
    "#     print(f'Making results file: {csv_out_path}')\n",
    "    with open(csv_out_path, 'w') as c:\n",
    "        writer = csv.writer(c, delimiter=',')\n",
    "\n",
    "        header = ['audio_filename'] + reorder_labels_for_submission(label_names)\n",
    "        writer.writerow(header)\n",
    "        data_rows = []\n",
    "        for filename in tqdm_notebook(os.listdir(basepath)):\n",
    "#         for index in range (0, len(Test_data[coarse_idx])):\n",
    "#             test_file = Test_data[coarse_idx][index]\n",
    "            # Only eval on non-augmented validation set data. TODO: remove extraneous files from validation dataset\n",
    "#             print(test_file)\n",
    "#             if '_pitch_changes-0_volume_changes-0_background_changes-None-None' not in test_file:\n",
    "            if '_pitch_changes-0_volume_changes-0_background_changes-None-None' not in filename:\n",
    "                continue\n",
    "            audio_filename = filename[0:9] + '.wav'\n",
    "            global total_files\n",
    "            total_files = total_files  + 1\n",
    "#  \n",
    "#                        print(test_file)\n",
    "#             audio_filename = test_file[0:9] + '.wav'\n",
    "            ###### load data for validation \n",
    "            ###### \n",
    "            spectrogram, vgg, label = joblib.load(os.path.join(basepath, filename))\n",
    "            \n",
    "            \n",
    "            \n",
    "            ### maybe not need to add this because when evaluating a certain class, \n",
    "            ### the program only evaluates what is clip annotated with that class\n",
    "#             label_true = np.where(label == 1)[0]\n",
    "#             label_name = [label_names[i] for i in label_true]\n",
    "# #             print(label_name)\n",
    "#             right_file = False\n",
    "#             for index in range(0, len(label_name)):\n",
    "#                 if(target_annotation == label_name[index]):\n",
    "#                     right_file = True\n",
    "                \n",
    "#             if(right_file == False):\n",
    "# #                 print(label_name, \" don't include for test\")\n",
    "#                 continue\n",
    "    \n",
    "                \n",
    "#             spectrogram, vgg, label = joblib.load(os.path.join(basepath, test_file))\n",
    "#             print('spectrogram.shape, label.shape')\n",
    "#             print(spectrogram.shape, emb.shape, label.shape)\n",
    "            spectrogram = np.expand_dims(spectrogram, axis=0)\n",
    "            spectrogram = np.expand_dims(spectrogram, axis=0)\n",
    "#             print('spectrogram.shape, label.shape')\n",
    "#             print(spectrogram.shape,label.shape)\n",
    "\n",
    "    #         print(vgg.flatten().shape)\n",
    "            vgg = torch.from_numpy(vgg.flatten().reshape((1, 1280)))\n",
    "            spectrogram = spectrogram.astype(np.float32)\n",
    "            spectrogram = torch.from_numpy(spectrogram)\n",
    "    #         print(spectrogram.shape, emb.shape, label.shape)\n",
    "            in_data = (spectrogram, vgg)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                results = model(in_data)\n",
    "                results = torch.sigmoid(results[0])\n",
    "                label_true = np.where(label == 1)[0]\n",
    "                label_name = [label_names[i] for i in label_true]\n",
    "#                 print(label_name)\n",
    "\n",
    "                results = results.detach().numpy()\n",
    "                if use_fine_model:\n",
    "#                     print(\"use_fine_model\")\n",
    "                    if FINE_TO_COARSE_LOGIC:\n",
    "                        print(\"FINE_TO_COARSE_LOGIC is true\")\n",
    "                        coarse_labels = []\n",
    "                        fine_label_names = label_names[NUM_COARSE_LABELS:]\n",
    "                        print(fine_label_names)\n",
    "                        coarse_label_dict = {i: [] for i in range(NUM_COARSE_LABELS)}\n",
    "                        for i, r in enumerate(results):\n",
    "        #                     print(fine_label_names[i][0])\n",
    "                            coarse_label_dict[int(fine_label_names[i][0])-1].append(r)\n",
    "                        for i in range(NUM_COARSE_LABELS):\n",
    "                            coarse_labels.append(max(coarse_label_dict[i]))\n",
    "        #                 print('coarse labels', coarse_labels)\n",
    "                        results = coarse_labels + list(results)\n",
    "                    else:\n",
    "#                         print(\"FINE_TO_COARSE_LOGIC is false\")\n",
    "                        full_results = np.zeros(NUM_TOTAL_LABELS)\n",
    "                        full_results[label_start : label_end] = results\n",
    "                        results = full_results\n",
    "                        \n",
    "                elif COARSE_WITH_FINE_TOP_LEVEL_MODEL:\n",
    "                    results = list(results)\n",
    "                else:\n",
    "                    # Coarse model.\n",
    "                    results = list(results) + [0 for i in range(NUM_FINE_LABELS)]\n",
    "\n",
    "                results = reorder_labels_for_submission(results)\n",
    "                #print (results)\n",
    "                data_rows.append([audio_filename] + results)\n",
    "    #             print([audio_filename] + results)\n",
    "        writer.writerows(data_rows)\n",
    "    \n",
    "    # Clean up.\n",
    "    del ckpt\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### N.B: checkpoint must have been trained with same model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Coarse predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making results file: csvs/results-20190715_141637-coarse.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d878472f320642c68921255befd76316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " make_results_csv(RESULT_CSV_COARSE_PATH, VGG_alt, COARSE_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Fine predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1_engine\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab022c1c1264fbbb94a0445b85584e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total_files  1401\n",
      "1       2_machinery-impact\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98b02b62890444182714d60a179edfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total_files  1844\n",
      "total_files  1844\n",
      "3       4_powered-saw\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf3386bb7f74b2ab6e1994b30ecbdfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total_files  2287\n",
      "4       5_alert-signal\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ede0f54f7e4e018f629722398217cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total_files  2730\n",
      "5       6_music\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c9f2ab71a645bcbb13e45e58b9f38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total_files  3173\n",
      "6       7_human-voice\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fc903c36b64fa184b4b46c43365686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "total_files  3616\n",
      "total_files  3616\n"
     ]
    }
   ],
   "source": [
    "for coarse_idx in range(NUM_COARSE_LABELS):\n",
    "#     print(coarse_idx)\n",
    "    label_start, label_end, num_fine_classes = get_label_range(coarse_idx)\n",
    "    make_fine_results_csv(RESULT_CSV_FINE_PATH_TEMPLATE, VGG_alt_fine, ckpt_paths_fine[coarse_idx], \n",
    "                     use_fine_model=True, coarse_idx=coarse_idx, \n",
    "                     label_start=label_start, label_end=label_end, num_fine_classes=num_fine_classes)\n",
    "    print(\"total_files \", total_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine separate prediction CSVs into final output CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load coarse-model results CSV.\n",
    "2. For each coarse class with a high score, copy in the fine-level results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csvs/results-20190715_141637-coarse.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>1-1_small-sounding-engine</th>\n",
       "      <th>1-2_medium-sounding-engine</th>\n",
       "      <th>1-3_large-sounding-engine</th>\n",
       "      <th>1-X_engine-of-uncertain-size</th>\n",
       "      <th>2-1_rock-drill</th>\n",
       "      <th>2-2_jackhammer</th>\n",
       "      <th>2-3_hoe-ram</th>\n",
       "      <th>2-4_pile-driver</th>\n",
       "      <th>2-X_other-unknown-impact-machinery</th>\n",
       "      <th>...</th>\n",
       "      <th>7-X_other-unknown-human-voice</th>\n",
       "      <th>8-1_dog-barking-whining</th>\n",
       "      <th>1_engine</th>\n",
       "      <th>2_machinery-impact</th>\n",
       "      <th>3_non-machinery-impact</th>\n",
       "      <th>4_powered-saw</th>\n",
       "      <th>5_alert-signal</th>\n",
       "      <th>6_music</th>\n",
       "      <th>7_human-voice</th>\n",
       "      <th>8_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00_001177.wav</td>\n",
       "      <td>0.038288</td>\n",
       "      <td>0.122052</td>\n",
       "      <td>0.502112</td>\n",
       "      <td>0.101482</td>\n",
       "      <td>1.838860e-03</td>\n",
       "      <td>8.821300e-04</td>\n",
       "      <td>6.156426e-04</td>\n",
       "      <td>2.825153e-05</td>\n",
       "      <td>0.032948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.696243</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.037064</td>\n",
       "      <td>0.007079</td>\n",
       "      <td>0.023692</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.012542</td>\n",
       "      <td>0.000551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04_000468.wav</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>1.651226e-08</td>\n",
       "      <td>7.369137e-07</td>\n",
       "      <td>2.464860e-07</td>\n",
       "      <td>1.526348e-04</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014872</td>\n",
       "      <td>0.029644</td>\n",
       "      <td>0.012437</td>\n",
       "      <td>0.015715</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.011788</td>\n",
       "      <td>0.922762</td>\n",
       "      <td>0.029466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04_000182.wav</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>0.065575</td>\n",
       "      <td>0.099614</td>\n",
       "      <td>0.026444</td>\n",
       "      <td>1.078371e-05</td>\n",
       "      <td>6.772748e-05</td>\n",
       "      <td>3.545732e-04</td>\n",
       "      <td>4.953779e-03</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110802</td>\n",
       "      <td>0.010844</td>\n",
       "      <td>0.236392</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>0.035246</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.040328</td>\n",
       "      <td>0.028849</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.010727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03_001573.wav</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.042999</td>\n",
       "      <td>0.016009</td>\n",
       "      <td>0.044127</td>\n",
       "      <td>1.119302e-04</td>\n",
       "      <td>5.963831e-04</td>\n",
       "      <td>9.065376e-06</td>\n",
       "      <td>4.337600e-04</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0.185584</td>\n",
       "      <td>0.082052</td>\n",
       "      <td>0.035761</td>\n",
       "      <td>0.035577</td>\n",
       "      <td>0.012118</td>\n",
       "      <td>0.456379</td>\n",
       "      <td>0.073907</td>\n",
       "      <td>0.181871</td>\n",
       "      <td>0.184687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04_000588.wav</td>\n",
       "      <td>0.015593</td>\n",
       "      <td>0.244084</td>\n",
       "      <td>0.639739</td>\n",
       "      <td>0.032929</td>\n",
       "      <td>9.380853e-04</td>\n",
       "      <td>1.698513e-03</td>\n",
       "      <td>2.567723e-04</td>\n",
       "      <td>2.031658e-09</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.005657</td>\n",
       "      <td>0.865977</td>\n",
       "      <td>0.020132</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.025869</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.005812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  audio_filename  1-1_small-sounding-engine  1-2_medium-sounding-engine  \\\n",
       "0  00_001177.wav                   0.038288                    0.122052   \n",
       "1  04_000468.wav                   0.001285                    0.004436   \n",
       "2  04_000182.wav                   0.017328                    0.065575   \n",
       "3  03_001573.wav                   0.006351                    0.042999   \n",
       "4  04_000588.wav                   0.015593                    0.244084   \n",
       "\n",
       "   1-3_large-sounding-engine  1-X_engine-of-uncertain-size  2-1_rock-drill  \\\n",
       "0                   0.502112                      0.101482    1.838860e-03   \n",
       "1                   0.001538                      0.001433    1.651226e-08   \n",
       "2                   0.099614                      0.026444    1.078371e-05   \n",
       "3                   0.016009                      0.044127    1.119302e-04   \n",
       "4                   0.639739                      0.032929    9.380853e-04   \n",
       "\n",
       "   2-2_jackhammer   2-3_hoe-ram  2-4_pile-driver  \\\n",
       "0    8.821300e-04  6.156426e-04     2.825153e-05   \n",
       "1    7.369137e-07  2.464860e-07     1.526348e-04   \n",
       "2    6.772748e-05  3.545732e-04     4.953779e-03   \n",
       "3    5.963831e-04  9.065376e-06     4.337600e-04   \n",
       "4    1.698513e-03  2.567723e-04     2.031658e-09   \n",
       "\n",
       "   2-X_other-unknown-impact-machinery  ...  7-X_other-unknown-human-voice  \\\n",
       "0                            0.032948  ...                       0.000232   \n",
       "1                            0.001204  ...                       0.014872   \n",
       "2                            0.026367  ...                       0.110802   \n",
       "3                            0.003769  ...                       0.008019   \n",
       "4                            0.001455  ...                       0.000043   \n",
       "\n",
       "   8-1_dog-barking-whining  1_engine  2_machinery-impact  \\\n",
       "0                 0.000566  0.696243            0.058200   \n",
       "1                 0.029644  0.012437            0.015715   \n",
       "2                 0.010844  0.236392            0.075319   \n",
       "3                 0.185584  0.082052            0.035761   \n",
       "4                 0.005657  0.865977            0.020132   \n",
       "\n",
       "   3_non-machinery-impact  4_powered-saw  5_alert-signal   6_music  \\\n",
       "0                0.037064       0.007079        0.023692  0.000129   \n",
       "1                0.003796       0.000192        0.005412  0.011788   \n",
       "2                0.035246       0.001487        0.040328  0.028849   \n",
       "3                0.035577       0.012118        0.456379  0.073907   \n",
       "4                0.001470       0.001156        0.025869  0.000029   \n",
       "\n",
       "   7_human-voice     8_dog  \n",
       "0       0.012542  0.000551  \n",
       "1       0.922762  0.029466  \n",
       "2       0.846842  0.010727  \n",
       "3       0.181871  0.184687  \n",
       "4       0.006563  0.005812  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(RESULT_CSV_COARSE_PATH)\n",
    "print(RESULT_CSV_COARSE_PATH)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5\n",
      "5    10\n",
      "10    11\n",
      "11    15\n",
      "15    20\n",
      "20    24\n",
      "24    29\n",
      "29    30\n"
     ]
    }
   ],
   "source": [
    "dfs_fine = defaultdict(lambda: None)\n",
    "label_ranges = {}\n",
    "for coarse_idx in range(NUM_COARSE_LABELS):\n",
    "    csv_path = RESULT_CSV_FINE_PATH_TEMPLATE % coarse_idx\n",
    "    label_start, label_end, _ = get_label_range(coarse_idx)\n",
    "     # convert from starting fine labels at col 8 to starting at col 1\n",
    "    label_start -= NUM_COARSE_LABELS - 1  # -1 is to account for audio_filename in col 0\n",
    "    label_end -= NUM_COARSE_LABELS - 1\n",
    "    label_ranges[coarse_idx] = (label_start, label_end)\n",
    "    print(label_start, \"  \", label_end)\n",
    "    if os.path.exists(csv_path):\n",
    "        dfs_fine[coarse_idx] = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (1, 5),\n",
       " 1: (5, 10),\n",
       " 2: (10, 11),\n",
       " 3: (11, 15),\n",
       " 4: (15, 20),\n",
       " 5: (20, 24),\n",
       " 6: (24, 29),\n",
       " 7: (29, 30)}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs_fine[1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(443, 38)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a42de2452c406fbbc468551959b75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=443), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm_notebook(range(len(df))):\n",
    "#     print(\"length \", len(df))\n",
    "#     print(\"df_fine \" , df_fine.values.shape)\n",
    "    # Find the coarse-predicitons that are over-threshold OR are max over all coarse categories.\n",
    "    # Find argmax.\n",
    "    coarse_preds = df.values[i][1 + NUM_FINE_LABELS:]\n",
    "#     print(coarse_preds)\n",
    "    best_coarse_idx = np.argmax(coarse_preds)\n",
    "    for coarse_idx in range(NUM_COARSE_LABELS):\n",
    "        start_idx, end_idx = label_ranges[coarse_idx]\n",
    "        coarse_prob = df.values[i][1 + NUM_FINE_LABELS + coarse_idx]\n",
    "#         print(coarse_preds)\n",
    "        if coarse_prob > COARSE_PREDICT_THRESHOLD or coarse_idx == best_coarse_idx:  # + 1 is because of filename in col 0\n",
    "            df_fine = dfs_fine[coarse_idx]\n",
    "#             print(type(df_fine))\n",
    "#             print(df_fine.shape)\n",
    "#             print(df_fine)\n",
    "            if df_fine is None:\n",
    "                assert end_idx - start_idx == 1\n",
    "                df.iloc[i, start_idx] = coarse_prob\n",
    "            else:\n",
    "                # Copy fine-predictions over into the results data.\n",
    "#                 print(start_idx, \"   \",  end_idx)\n",
    "#                 print(i)\n",
    "#                 print(\"coarse_idx \", coarse_idx)\n",
    "#                 print(start_idx, \"   \", end_idx)\n",
    "#                 print(\"df_fine \" , df_fine.values.shape)\n",
    "#                 print(\"df_fine \" , df_fine.values.shape)\n",
    "#                 print(df_fine.values[i][0])\n",
    "#                 print(len(df_fine.values[i]))  \n",
    "#                 print(df_fine.values[i][start_idx:end_idx])\n",
    "#                 print()\n",
    "                df.iloc[i, start_idx:end_idx] = df_fine.values[i][start_idx:end_idx]\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_filename</th>\n",
       "      <th>1-1_small-sounding-engine</th>\n",
       "      <th>1-2_medium-sounding-engine</th>\n",
       "      <th>1-3_large-sounding-engine</th>\n",
       "      <th>1-X_engine-of-uncertain-size</th>\n",
       "      <th>2-1_rock-drill</th>\n",
       "      <th>2-2_jackhammer</th>\n",
       "      <th>2-3_hoe-ram</th>\n",
       "      <th>2-4_pile-driver</th>\n",
       "      <th>2-X_other-unknown-impact-machinery</th>\n",
       "      <th>...</th>\n",
       "      <th>7-X_other-unknown-human-voice</th>\n",
       "      <th>8-1_dog-barking-whining</th>\n",
       "      <th>1_engine</th>\n",
       "      <th>2_machinery-impact</th>\n",
       "      <th>3_non-machinery-impact</th>\n",
       "      <th>4_powered-saw</th>\n",
       "      <th>5_alert-signal</th>\n",
       "      <th>6_music</th>\n",
       "      <th>7_human-voice</th>\n",
       "      <th>8_dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00_001177.wav</td>\n",
       "      <td>0.019638</td>\n",
       "      <td>0.083289</td>\n",
       "      <td>0.498525</td>\n",
       "      <td>0.027672</td>\n",
       "      <td>1.838860e-03</td>\n",
       "      <td>8.821300e-04</td>\n",
       "      <td>6.156426e-04</td>\n",
       "      <td>2.825153e-05</td>\n",
       "      <td>0.032948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.696243</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.037064</td>\n",
       "      <td>0.007079</td>\n",
       "      <td>0.023692</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.012542</td>\n",
       "      <td>0.000551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04_000468.wav</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>1.651226e-08</td>\n",
       "      <td>7.369137e-07</td>\n",
       "      <td>2.464860e-07</td>\n",
       "      <td>1.526348e-04</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>0.029644</td>\n",
       "      <td>0.012437</td>\n",
       "      <td>0.015715</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.011788</td>\n",
       "      <td>0.922762</td>\n",
       "      <td>0.029466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04_000182.wav</td>\n",
       "      <td>0.017328</td>\n",
       "      <td>0.065575</td>\n",
       "      <td>0.099614</td>\n",
       "      <td>0.026444</td>\n",
       "      <td>1.078371e-05</td>\n",
       "      <td>6.772748e-05</td>\n",
       "      <td>3.545732e-04</td>\n",
       "      <td>4.953779e-03</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.010844</td>\n",
       "      <td>0.236392</td>\n",
       "      <td>0.075319</td>\n",
       "      <td>0.035246</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>0.040328</td>\n",
       "      <td>0.028849</td>\n",
       "      <td>0.846842</td>\n",
       "      <td>0.010727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03_001573.wav</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.042999</td>\n",
       "      <td>0.016009</td>\n",
       "      <td>0.044127</td>\n",
       "      <td>1.119302e-04</td>\n",
       "      <td>5.963831e-04</td>\n",
       "      <td>9.065376e-06</td>\n",
       "      <td>4.337600e-04</td>\n",
       "      <td>0.003769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>0.185584</td>\n",
       "      <td>0.082052</td>\n",
       "      <td>0.035761</td>\n",
       "      <td>0.035577</td>\n",
       "      <td>0.012118</td>\n",
       "      <td>0.456379</td>\n",
       "      <td>0.073907</td>\n",
       "      <td>0.181871</td>\n",
       "      <td>0.184687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04_000588.wav</td>\n",
       "      <td>0.016314</td>\n",
       "      <td>0.157480</td>\n",
       "      <td>0.415551</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>9.380853e-04</td>\n",
       "      <td>1.698513e-03</td>\n",
       "      <td>2.567723e-04</td>\n",
       "      <td>2.031658e-09</td>\n",
       "      <td>0.001455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.005657</td>\n",
       "      <td>0.865977</td>\n",
       "      <td>0.020132</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.025869</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.006563</td>\n",
       "      <td>0.005812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  audio_filename  1-1_small-sounding-engine  1-2_medium-sounding-engine  \\\n",
       "0  00_001177.wav                   0.019638                    0.083289   \n",
       "1  04_000468.wav                   0.001285                    0.004436   \n",
       "2  04_000182.wav                   0.017328                    0.065575   \n",
       "3  03_001573.wav                   0.006351                    0.042999   \n",
       "4  04_000588.wav                   0.016314                    0.157480   \n",
       "\n",
       "   1-3_large-sounding-engine  1-X_engine-of-uncertain-size  2-1_rock-drill  \\\n",
       "0                   0.498525                      0.027672    1.838860e-03   \n",
       "1                   0.001538                      0.001433    1.651226e-08   \n",
       "2                   0.099614                      0.026444    1.078371e-05   \n",
       "3                   0.016009                      0.044127    1.119302e-04   \n",
       "4                   0.415551                      0.015849    9.380853e-04   \n",
       "\n",
       "   2-2_jackhammer   2-3_hoe-ram  2-4_pile-driver  \\\n",
       "0    8.821300e-04  6.156426e-04     2.825153e-05   \n",
       "1    7.369137e-07  2.464860e-07     1.526348e-04   \n",
       "2    6.772748e-05  3.545732e-04     4.953779e-03   \n",
       "3    5.963831e-04  9.065376e-06     4.337600e-04   \n",
       "4    1.698513e-03  2.567723e-04     2.031658e-09   \n",
       "\n",
       "   2-X_other-unknown-impact-machinery  ...  7-X_other-unknown-human-voice  \\\n",
       "0                            0.032948  ...                       0.000232   \n",
       "1                            0.001204  ...                       0.005020   \n",
       "2                            0.026367  ...                       0.005362   \n",
       "3                            0.003769  ...                       0.008019   \n",
       "4                            0.001455  ...                       0.000043   \n",
       "\n",
       "   8-1_dog-barking-whining  1_engine  2_machinery-impact  \\\n",
       "0                 0.000566  0.696243            0.058200   \n",
       "1                 0.029644  0.012437            0.015715   \n",
       "2                 0.010844  0.236392            0.075319   \n",
       "3                 0.185584  0.082052            0.035761   \n",
       "4                 0.005657  0.865977            0.020132   \n",
       "\n",
       "   3_non-machinery-impact  4_powered-saw  5_alert-signal   6_music  \\\n",
       "0                0.037064       0.007079        0.023692  0.000129   \n",
       "1                0.003796       0.000192        0.005412  0.011788   \n",
       "2                0.035246       0.001487        0.040328  0.028849   \n",
       "3                0.035577       0.012118        0.456379  0.073907   \n",
       "4                0.001470       0.001156        0.025869  0.000029   \n",
       "\n",
       "   7_human-voice     8_dog  \n",
       "0       0.012542  0.000551  \n",
       "1       0.922762  0.029466  \n",
       "2       0.846842  0.010727  \n",
       "3       0.181871  0.184687  \n",
       "4       0.006563  0.005812  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(RESULT_CSV_FINAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'csvs/results-20190715_141637-final.csv'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT_CSV_FINAL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Fine level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.6254867629685286\n",
      " * Micro F1-score (@0.5): 0.4909819639278557\n",
      " * Macro AUPRC:           0.3857762522385675\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.6084437663572311\n",
      "      - 2: 0.14288025423208833\n",
      "      - 3: 0.3336595526102611\n",
      "      - 4: 0.33066483112050044\n",
      "      - 5: 0.668508235927582\n",
      "      - 6: 0.1563059224638172\n",
      "      - 7: 0.8457474551970598\n",
      "      - 8: 0.0\n",
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Coarse level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.7687132764444584\n",
      " * Micro F1-score (@0.5): 0.5328109696376102\n",
      " * Macro AUPRC:           0.5552582865865167\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.8178125638838614\n",
      "      - 2: 0.42810526358580453\n",
      "      - 3: 0.3332328931822347\n",
      "      - 4: 0.6770075945049289\n",
      "      - 5: 0.8674275089257218\n",
      "      - 6: 0.37801009220794807\n",
      "      - 7: 0.9404703764016337\n",
      "      - 8: 0.0\n"
     ]
    }
   ],
   "source": [
    "# run a command similar to this on the command line to get results  # 20190609_031224\n",
    "\n",
    "##  This is the result from /dcase/output/models_Jianyu/one-part-1-models-logmel-best6-originalmodel_rmsprop-learningratechangebiggerinCallback\n",
    "##  train_branches_20190713_1_one_part_one_model_OriginalModel_LeanringRateChangeMuchlower.py\n",
    "if not LINUX:\n",
    "    !python evaluate_predictions.py results_2019-5-6-aug.csv \"D:\\DCASE_2019\\annotations.csv\" \"D:\\DCASE_2019\\dcase-ust-taxonomy.yaml\"\n",
    "else:\n",
    "    !python evaluate_predictions.py csvs/results-20190713_112132-final.csv /dcase/datasets-dcase-2019-5/annotations.csv /dcase/datasets-dcase-2019-5/dcase-ust-taxonomy.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Fine level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.6352275033460464\n",
      " * Micro F1-score (@0.5): 0.473953013278856\n",
      " * Macro AUPRC:           0.3859955932100825\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.6421604848641354\n",
      "      - 2: 0.14290489694838895\n",
      "      - 3: 0.3336595526102611\n",
      "      - 4: 0.28717011575218754\n",
      "      - 5: 0.6714119230258853\n",
      "      - 6: 0.1563059224638172\n",
      "      - 7: 0.8543518500159846\n",
      "      - 8: 0.0\n",
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Coarse level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.7687132764444584\n",
      " * Micro F1-score (@0.5): 0.5328109696376102\n",
      " * Macro AUPRC:           0.5552582865865167\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.8178125638838614\n",
      "      - 2: 0.42810526358580453\n",
      "      - 3: 0.3332328931822347\n",
      "      - 4: 0.6770075945049289\n",
      "      - 5: 0.8674275089257218\n",
      "      - 6: 0.37801009220794807\n",
      "      - 7: 0.9404703764016337\n",
      "      - 8: 0.0\n"
     ]
    }
   ],
   "source": [
    "# run a command similar to this on the command line to get results  # 20190609_031224\n",
    "\n",
    "##  This is the result from /dcase/output/models_Jianyu/one-part-1-models-logmel-best6-originalmodel_rmsprop-learningratechangebiggerinCallback\n",
    "##  train_branches_20190713_1_one_part_one_model_OriginalModel_LeanringRateChangeMuchlower.py\n",
    "if not LINUX:\n",
    "    !python evaluate_predictions.py results_2019-5-6-aug.csv \"D:\\DCASE_2019\\annotations.csv\" \"D:\\DCASE_2019\\dcase-ust-taxonomy.yaml\"\n",
    "else:\n",
    "    !python evaluate_predictions.py csvs/results-20190713_103400-final.csv /dcase/datasets-dcase-2019-5/annotations.csv /dcase/datasets-dcase-2019-5/dcase-ust-taxonomy.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Fine level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.6429200022744848\n",
      " * Micro F1-score (@0.5): 0.5163853028798411\n",
      " * Macro AUPRC:           0.41221486377413197\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.6866141325176544\n",
      "      - 2: 0.12112664107420393\n",
      "      - 3: 0.4020905123120714\n",
      "      - 4: 0.3870551691374258\n",
      "      - 5: 0.659413704156418\n",
      "      - 6: 0.251310185085831\n",
      "      - 7: 0.7847798844483058\n",
      "      - 8: 0.005328681461145428\n",
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Coarse level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.7866247951279302\n",
      " * Micro F1-score (@0.5): 0.6088560885608856\n",
      " * Macro AUPRC:           0.5789589780231039\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.8353362187853394\n",
      "      - 2: 0.4327457086690561\n",
      "      - 3: 0.40356804631393906\n",
      "      - 4: 0.7018285524935755\n",
      "      - 5: 0.8556952720570562\n",
      "      - 6: 0.45479025811812124\n",
      "      - 7: 0.942311730093642\n",
      "      - 8: 0.005396037654102171\n"
     ]
    }
   ],
   "source": [
    "#################################  this result is add to the report \n",
    "\n",
    "\n",
    "\n",
    "# run a command similar to this on the command line to get results  # 20190609_031224\n",
    "\n",
    "##  This is the result from /dcase/output/models_Jianyu/one-part-1-models-logmel-best5-rmsprop-learningratechangebiggerinCallback\n",
    "##  train_branches_20190711_3_one_part_one_model_LeanringRateChangeSlower.py\n",
    "\n",
    "if not LINUX:\n",
    "    !python evaluate_predictions.py results_2019-5-6-aug.csv \"D:\\DCASE_2019\\annotations.csv\" \"D:\\DCASE_2019\\dcase-ust-taxonomy.yaml\"\n",
    "else:\n",
    "    !python evaluate_predictions.py csvs/results-20190715_141637-final.csv /dcase/datasets-dcase-2019-5/annotations.csv /dcase/datasets-dcase-2019-5/dcase-ust-taxonomy.yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Fine level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.6496101347404405\n",
      " * Micro F1-score (@0.5): 0.5005045408678103\n",
      " * Macro AUPRC:           0.4106011898721246\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.6689075318877663\n",
      "      - 2: 0.13501270495855258\n",
      "      - 3: 0.4020905123120714\n",
      "      - 4: 0.33732866485418367\n",
      "      - 5: 0.6505729200529182\n",
      "      - 6: 0.251310185085831\n",
      "      - 7: 0.834258318364528\n",
      "      - 8: 0.005328681461145428\n",
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Coarse level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.7866247951279302\n",
      " * Micro F1-score (@0.5): 0.6088560885608856\n",
      " * Macro AUPRC:           0.5789589780231039\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.8353362187853394\n",
      "      - 2: 0.4327457086690561\n",
      "      - 3: 0.40356804631393906\n",
      "      - 4: 0.7018285524935755\n",
      "      - 5: 0.8556952720570562\n",
      "      - 6: 0.45479025811812124\n",
      "      - 7: 0.942311730093642\n",
      "      - 8: 0.005396037654102171\n"
     ]
    }
   ],
   "source": [
    "# run a command similar to this on the command line to get results  # 20190609_031224\n",
    "\n",
    "##  This is the result from /dcase/output/models_Jianyu/one-part-1-models-logmel-best4-rmsprop-learningratechangebiggerinCallback\n",
    "##  train_branches_20190711_3_one_part_one_model_LeanringRateChangeSlower.py\n",
    "if not LINUX:\n",
    "    !python evaluate_predictions.py results_2019-5-6-aug.csv \"D:\\DCASE_2019\\annotations.csv\" \"D:\\DCASE_2019\\dcase-ust-taxonomy.yaml\"\n",
    "else:\n",
    "    !python evaluate_predictions.py csvs/results-20190715_141637-final.csv /dcase/datasets-dcase-2019-5/annotations.csv /dcase/datasets-dcase-2019-5/dcase-ust-taxonomy.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Fine level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.6363211133162249\n",
      " * Micro F1-score (@0.5): 0.4710743801652893\n",
      " * Macro AUPRC:           0.38647299543112723\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.654099839967299\n",
      "      - 2: 0.1471312850330832\n",
      "      - 3: 0.3336595526102611\n",
      "      - 4: 0.3052075983279423\n",
      "      - 5: 0.6632979242445739\n",
      "      - 6: 0.1563059224638172\n",
      "      - 7: 0.8320818408020411\n",
      "      - 8: 0.0\n",
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Coarse level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.7687132764444584\n",
      " * Micro F1-score (@0.5): 0.5328109696376102\n",
      " * Macro AUPRC:           0.5552582865865167\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.8178125638838614\n",
      "      - 2: 0.42810526358580453\n",
      "      - 3: 0.3332328931822347\n",
      "      - 4: 0.6770075945049289\n",
      "      - 5: 0.8674275089257218\n",
      "      - 6: 0.37801009220794807\n",
      "      - 7: 0.9404703764016337\n",
      "      - 8: 0.0\n"
     ]
    }
   ],
   "source": [
    "# run a command similar to this on the command line to get results  # 20190609_031224\n",
    "\n",
    "##  This is the result from one-part-1-models-logmel-best2-rmsp -dropoutlow\n",
    "##  train_branches_20190711_2_one_part_one_model_no_dropout.py\n",
    "if not LINUX:\n",
    "    !python evaluate_predictions.py results_2019-5-6-aug.csv \"D:\\DCASE_2019\\annotations.csv\" \"D:\\DCASE_2019\\dcase-ust-taxonomy.yaml\"\n",
    "else:\n",
    "    !python evaluate_predictions.py csvs/results-20190712_133112-final.csv /dcase/datasets-dcase-2019-5/annotations.csv /dcase/datasets-dcase-2019-5/dcase-ust-taxonomy.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Fine level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.6231496003383689\n",
      " * Micro F1-score (@0.5): 0.5010060362173039\n",
      " * Macro AUPRC:           0.38623738657528395\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.6343790243886206\n",
      "      - 2: 0.16253583808623515\n",
      "      - 3: 0.3336595526102611\n",
      "      - 4: 0.32327465520753845\n",
      "      - 5: 0.6664129472290485\n",
      "      - 6: 0.1563059224638172\n",
      "      - 7: 0.8133311526167504\n",
      "      - 8: 0.0\n",
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Coarse level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.7687132764444584\n",
      " * Micro F1-score (@0.5): 0.5328109696376102\n",
      " * Macro AUPRC:           0.5552582865865167\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.8178125638838614\n",
      "      - 2: 0.42810526358580453\n",
      "      - 3: 0.3332328931822347\n",
      "      - 4: 0.6770075945049289\n",
      "      - 5: 0.8674275089257218\n",
      "      - 6: 0.37801009220794807\n",
      "      - 7: 0.9404703764016337\n",
      "      - 8: 0.0\n"
     ]
    }
   ],
   "source": [
    "# run a command similar to this on the command line to get results  # 20190609_031224\n",
    "\n",
    "##  This is the result from one-part-1-models-logmel-best2-rmsp \n",
    "##  train_branches_20190711_2_one_part_one_model.py     optimizer = rmsprop \n",
    "if not LINUX:\n",
    "    !python evaluate_predictions.py results_2019-5-6-aug.csv \"D:\\DCASE_2019\\annotations.csv\" \"D:\\DCASE_2019\\dcase-ust-taxonomy.yaml\"\n",
    "else:\n",
    "    !python evaluate_predictions.py csvs/results-20190712_113151-final.csv /dcase/datasets-dcase-2019-5/annotations.csv /dcase/datasets-dcase-2019-5/dcase-ust-taxonomy.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Fine level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.6361358901902983\n",
      " * Micro F1-score (@0.5): 0.4969818913480885\n",
      " * Macro AUPRC:           0.39259460285229086\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.6196898192139044\n",
      "      - 2: 0.1658941086630264\n",
      "      - 3: 0.3336595526102611\n",
      "      - 4: 0.34424915961788777\n",
      "      - 5: 0.6686388310242353\n",
      "      - 6: 0.1563059224638172\n",
      "      - 7: 0.8523194292251949\n",
      "      - 8: 0.0\n",
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Coarse level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.7687132764444584\n",
      " * Micro F1-score (@0.5): 0.5328109696376102\n",
      " * Macro AUPRC:           0.5552582865865167\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.8178125638838614\n",
      "      - 2: 0.42810526358580453\n",
      "      - 3: 0.3332328931822347\n",
      "      - 4: 0.6770075945049289\n",
      "      - 5: 0.8674275089257218\n",
      "      - 6: 0.37801009220794807\n",
      "      - 7: 0.9404703764016337\n",
      "      - 8: 0.0\n"
     ]
    }
   ],
   "source": [
    "# run a command similar to this on the command line to get results  # 20190609_031224\n",
    "\n",
    "##  This is the result from one-part-1-models-logmel-best \n",
    "##  train_branches_20190711_2_one_part_one_model.py     optimizer = adam  \n",
    "if not LINUX:\n",
    "    !python evaluate_predictions.py results_2019-5-6-aug.csv \"D:\\DCASE_2019\\annotations.csv\" \"D:\\DCASE_2019\\dcase-ust-taxonomy.yaml\"\n",
    "else:\n",
    "    !python evaluate_predictions.py csvs/results-20190712_095434-final.csv /dcase/datasets-dcase-2019-5/annotations.csv /dcase/datasets-dcase-2019-5/dcase-ust-taxonomy.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Fine level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.6560867707337048\n",
      " * Micro F1-score (@0.5): 0.3982202447163515\n",
      " * Macro AUPRC:           0.40059566061982355\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.6405304300056462\n",
      "      - 2: 0.21380721739093014\n",
      "      - 3: 0.3336595526102611\n",
      "      - 4: 0.2761679795550256\n",
      "      - 5: 0.70229675965\n",
      "      - 6: 0.1563059224638172\n",
      "      - 7: 0.8819974232829082\n",
      "      - 8: 0.0\n",
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Coarse level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.7687132764444584\n",
      " * Micro F1-score (@0.5): 0.5328109696376102\n",
      " * Macro AUPRC:           0.5552582865865167\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.8178125638838614\n",
      "      - 2: 0.42810526358580453\n",
      "      - 3: 0.3332328931822347\n",
      "      - 4: 0.6770075945049289\n",
      "      - 5: 0.8674275089257218\n",
      "      - 6: 0.37801009220794807\n",
      "      - 7: 0.9404703764016337\n",
      "      - 8: 0.0\n"
     ]
    }
   ],
   "source": [
    "# run a command similar to this on the command line to get results  # 20190609_031224\n",
    "\n",
    "##  not sure which result it comes from, maybe the /dcase/output/model/best/   since it is also June 10\n",
    "if not LINUX:\n",
    "    !python evaluate_predictions.py results_2019-5-6-aug.csv \"D:\\DCASE_2019\\annotations.csv\" \"D:\\DCASE_2019\\dcase-ust-taxonomy.yaml\"\n",
    "else:\n",
    "    !python evaluate_predictions.py csvs/results-20190610_231917-final.csv /dcase/datasets-dcase-2019-5/annotations.csv /dcase/datasets-dcase-2019-5/dcase-ust-taxonomy.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python extract_embedding.py \"D:\\DCASE_2019\\annotations.csv\" $SONYC_UST_PATH/data $SONYC_UST_PATH/features $SONYC_UST_PATH/vggish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Fine level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.6293865759512395\n",
      " * Micro F1-score (@0.5): 0.49899799599198397\n",
      " * Macro AUPRC:           0.39545724490363043\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.6044598965450919\n",
      "      - 2: 0.20886913422339365\n",
      "      - 3: 0.3336595526102611\n",
      "      - 4: 0.3436435915466351\n",
      "      - 5: 0.6959986741419814\n",
      "      - 6: 0.1563059224638172\n",
      "      - 7: 0.8207211876978632\n",
      "      - 8: 0.0\n",
      "sys:1: DtypeWarning: Columns (40,54,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "evaluate_predictions.py:36: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  thresh_0pt5_idx = (eval_df['threshold'] >= 0.5).nonzero()[0][0]\n",
      "Coarse level evaluation:\n",
      "======================\n",
      " * Micro AUPRC:           0.7687132764444584\n",
      " * Micro F1-score (@0.5): 0.5328109696376102\n",
      " * Macro AUPRC:           0.5552582865865167\n",
      " * Coarse Tag AUPRC:\n",
      "      - 1: 0.8178125638838614\n",
      "      - 2: 0.42810526358580453\n",
      "      - 3: 0.3332328931822347\n",
      "      - 4: 0.6770075945049289\n",
      "      - 5: 0.8674275089257218\n",
      "      - 6: 0.37801009220794807\n",
      "      - 7: 0.9404703764016337\n",
      "      - 8: 0.0\n"
     ]
    }
   ],
   "source": [
    "# run a command similar to this on the command line to get results  # 20190609_031224\n",
    "\n",
    "##  this is actuall  results  from  /dcase/trained-models-branches2/20190607.......\n",
    "\n",
    "\n",
    "if not LINUX:\n",
    "    !python evaluate_predictions.py results_2019-5-6-aug.csv \"D:\\DCASE_2019\\annotations.csv\" \"D:\\DCASE_2019\\dcase-ust-taxonomy.yaml\"\n",
    "else:\n",
    "    !python evaluate_predictions.py csvs/results-20190712_084152-final.csv /dcase/datasets-dcase-2019-5/annotations.csv /dcase/datasets-dcase-2019-5/dcase-ust-taxonomy.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
