{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modied from: https://github.com/sonyc-project/urban-sound-tagging-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gzip\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from vggish import vggish_input\n",
    "from vggish import vggish_postprocess\n",
    "from vggish import vggish_slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = r\"D:\\DCASE_2019\\audio\\train\" # where the audio files are\n",
    "output_dir = r\"D:\\DCASE_2019\\audio\\features_train\" # where to save vgg embeddigns\n",
    "vggish_resource_dir = r\"D:\\DCASE_2019\\baseline\\urban-sound-tagging-baseline\\urban-sound-tagging-baseline\\vggish\" # where the vgg checkpoint file is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_extract_vggish_embedding(frame_duration=.96, hop_duration=.96, \n",
    "                                  input_op_name='vggish/input_features',\n",
    "                                  output_op_name='vggish/embedding', \n",
    "                                  embedding_size=128, resources_dir=None):\n",
    "    \"\"\"\n",
    "    Creates a coroutine generator for extracting and saving VGGish embeddings\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame_duration\n",
    "    hop_duration\n",
    "    input_op_name\n",
    "    output_op_name\n",
    "    embedding_size\n",
    "    resources_dir\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coroutine\n",
    "\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        'frame_win_sec': frame_duration,\n",
    "        'frame_hop_sec': hop_duration,\n",
    "        'embedding_size': embedding_size\n",
    "    }\n",
    "    print(params)\n",
    "    if not resources_dir:\n",
    "        resources_dir = os.path.join(os.path.dirname(__file__), 'vggish/resources')\n",
    "\n",
    "    pca_params_path = os.path.join(resources_dir, 'vggish_pca_params.npz')\n",
    "    model_path = os.path.join(resources_dir, 'vggish_model.ckpt')\n",
    "\n",
    "    try:\n",
    "        with tf.Graph().as_default(), tf.Session() as sess:\n",
    "            # Define the model in inference mode, load the checkpoint, and\n",
    "            # locate input and output tensors.\n",
    "            net = vggish_slim.define_vggish_slim(training=False, **params)\n",
    "            vggish_slim.load_vggish_slim_checkpoint(sess, model_path, **params)\n",
    "            print(dir(net))\n",
    "            quit()\n",
    "            while True:\n",
    "                # We use a coroutine to more easily keep open the Tensorflow contexts\n",
    "                # without having to constantly reload the model\n",
    "                audio_path, output_path = (yield)\n",
    "\n",
    "                if os.path.exists(output_path):\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    examples_batch = vggish_input.wavfile_to_examples(audio_path, **params)\n",
    "                except ValueError:\n",
    "                    print(\"Error opening {}. Skipping...\".format(audio_path))\n",
    "                    continue\n",
    "\n",
    "                # Prepare a postprocessor to munge the model embeddings.\n",
    "                pproc = vggish_postprocess.Postprocessor(pca_params_path, **params)\n",
    "\n",
    "                input_tensor_name = input_op_name + ':0'\n",
    "                output_tensor_name = output_op_name + ':0'\n",
    "\n",
    "                features_tensor = sess.graph.get_tensor_by_name(input_tensor_name)\n",
    "                embedding_tensor = sess.graph.get_tensor_by_name(output_tensor_name)\n",
    "\n",
    "                # Run inference and postprocessing.\n",
    "                [embedding_batch] = sess.run([embedding_tensor],\n",
    "                                             feed_dict={features_tensor: examples_batch})\n",
    "\n",
    "                emb = pproc.postprocess(embedding_batch, **params).astype(np.float32)\n",
    "\n",
    "                with gzip.open(output_path, 'wb') as f:\n",
    "                    emb.dump(f)\n",
    "\n",
    "    except GeneratorExit:\n",
    "        print('pass')\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings_vggish(dataset_dir, output_dir,\n",
    "                              vggish_resource_dir, frame_duration=0.96,\n",
    "                              hop_duration=0.96, progress=True,\n",
    "                              vggish_embedding_size=128):\n",
    "    \"\"\"\n",
    "    Extract embeddings for files annotated in the SONYC annotation file and save them to disk.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_dir\n",
    "    output_dir\n",
    "    vggish_resource_dir\n",
    "    frame_duration\n",
    "    hop_duration\n",
    "    progress\n",
    "    vggish_embedding_size\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"* Loading annotations.\")\n",
    "#     annotation_data = pd.read_csv(annotation_path).sort_values('audio_filename')\n",
    "\n",
    "    extract_vggish_embedding = make_extract_vggish_embedding(frame_duration, hop_duration,\n",
    "        input_op_name='vggish/input_features', output_op_name='vggish/embedding',\n",
    "        resources_dir=vggish_resource_dir, embedding_size=vggish_embedding_size)\n",
    "    # Start coroutine\n",
    "    next(extract_vggish_embedding)\n",
    "\n",
    "    out_dir = os.path.join(output_dir, 'vggish')\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    print(\"* Extracting embeddings.\")\n",
    "    for file in os.listdir(dataset_dir):\n",
    "        audio_path = os.path.join(dataset_dir, file)\n",
    "        filename, _ = os.path.splitext(file)\n",
    "        emb_path = os.path.join(out_dir, filename + '.npy.gz')\n",
    "        extract_vggish_embedding.send((audio_path, emb_path))\n",
    "\n",
    "    extract_vggish_embedding.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_embeddings_vggish(dataset_dir, output_dir, vggish_resource_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
