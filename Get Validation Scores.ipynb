{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv, re\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# from audio_cnn_poutyne import NeuralNetwork, VGG_alt, OpenL3, TEST_LOADER, device\n",
    "from train_coarse import VGG_alt, TEST_LOADER, device\n",
    "\n",
    "from load_dataset import AudioDataset\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"models/20190610_170308_coarse=0.787_fine=0.646.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## checkpoint must have been trained with same model architecture\n",
    "\n",
    "# model = NeuralNetwork()\n",
    "model = VGG_alt()\n",
    "# model = OpenL3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # experiment; ignore for now\n",
    "\n",
    "# class NN_Embeddings(nn.Module):\n",
    "#     def __init__(self, original_model):\n",
    "#         super(NN_Embeddings, self).__init__()\n",
    "#         self.features = nn.Sequential(*list(original_model.children())[:-4])\n",
    "        \n",
    "#     def forward(self, x):\n",
    "# #         print(x.shape)\n",
    "#         x = self.features(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # testing visualization; ignore for now\n",
    "\n",
    "# emb = model_2(torch.from_numpy(np.zeros((1, 1, 128, 862)).astype(np.float32)))\n",
    "\n",
    "# img_array = emb.detach().numpy()\n",
    "# print(img_array.shape)\n",
    "# print(np.sqrt(256))\n",
    "# print(img_array[0].shape)\n",
    "# img_array = img_array.reshape((32, 32))\n",
    "# plt.imshow(img_array, cmap='hot', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-orders output as [fine, coarse] to match demo .csv file (maybe not necessary)\n",
    "def reorder_labels_for_submission(list_or_array):\n",
    "    if type(list_or_array) == torch.Tensor:\n",
    "        list_or_array = list(list_or_array.to('cpu').numpy())\n",
    "    list_or_array = list(list_or_array)\n",
    "    return list_or_array[8:] + list_or_array[0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process label names\n",
    "label_names = joblib.load('label_order.pkl')\n",
    "label_names = [re.sub('_presence', '', label_names[i]) for i in range(len(label_names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FINE = False\n",
    "COARSE = False\n",
    "EMBED = True\n",
    "\n",
    "with open('results_2019-5-6-aug.csv', 'w') as c:\n",
    "    writer = csv.writer(c, delimiter=',')\n",
    "    \n",
    "    header = ['audio_filename'] + reorder_labels_for_submission(label_names)\n",
    "    writer.writerow(header)\n",
    "    basepath = r\"D:\\repos\\Data-Processing\\audio\\validate_spec_vgg\"\n",
    "    data_rows = []\n",
    "    for filename in os.listdir(basepath):\n",
    "        audio_filename = filename[0:9] + '.wav'\n",
    "        if EMBED:\n",
    "            spectrogram, vgg, label = joblib.load(os.path.join(basepath, filename)) #emb\n",
    "    #         print(spectrogram.shape, emb.shape, label.shape)\n",
    "            spectrogram = np.expand_dims(spectrogram, axis=0)\n",
    "            spectrogram = np.expand_dims(spectrogram, axis=0)\n",
    "#             emb = emb.reshape((1, 256, 192))\n",
    "#             emb = np.expand_dims(emb, axis=0)\n",
    "#             emb = torch.from_numpy(emb)\n",
    "    #         print(vgg.flatten().shape)\n",
    "            vgg = torch.from_numpy(vgg.flatten().reshape((1, 1280)))\n",
    "            spectrogram = spectrogram.astype(np.float32)\n",
    "            spectrogram = torch.from_numpy(spectrogram)\n",
    "    #         print(spectrogram.shape, emb.shape, label.shape)\n",
    "    #         print(spectrogram.shape)\n",
    "    #         spectrogram.to('cuda')\n",
    "    #         print(vgg.shape, emb.shape)\n",
    "            in_data = (spectrogram, vgg) #emb\n",
    "        else:\n",
    "            spectrogram, label = joblib.load(os.path.join(basepath, filename))\n",
    "            spectrogram = np.expand_dims(spectrogram, axis=0)\n",
    "            spectrogram = np.expand_dims(spectrogram, axis=0)\n",
    "            spectrogram = spectrogram.astype(np.float32)\n",
    "            spectrogram = torch.from_numpy(spectrogram)\n",
    "            in_data = (spectrogram) #emb\n",
    "        with torch.no_grad():\n",
    "            results = model(in_data)\n",
    "#             print(len(results[0]))\n",
    "            results = torch.sigmoid(results[0])\n",
    "            print(label)\n",
    "            print(results)\n",
    "            print()\n",
    "#             img_array = emb.detach().numpy()\n",
    "#             print()\n",
    "            label_true = np.where(label == 1)[0]\n",
    "            label_name = [label_names[i] for i in label_true]\n",
    "#             print(label_name)\n",
    "#             img_array = img_array.reshape((16, 16))\n",
    "#             plt.imshow(img_array, cmap='hot', interpolation='nearest')\n",
    "#             plt.show()\n",
    "#             print(results.shape)\n",
    "            results = results\n",
    "            results = results.detach().numpy()\n",
    "            if FINE:\n",
    "                coarse_labels = []\n",
    "                fine_label_names = label_names[8:]\n",
    "                coarse_label_dict = {i: [] for i in range(8)}\n",
    "                for i, r in enumerate(results):\n",
    "#                     print(fine_label_names[i][0])\n",
    "                    coarse_label_dict[int(fine_label_names[i][0])-1].append(r)\n",
    "                for i in range(8):\n",
    "                    coarse_labels.append(max(coarse_label_dict[i]))\n",
    "#                 print('coarse labels', coarse_labels)\n",
    "                results = coarse_labels + list(results)\n",
    "            if COARSE:\n",
    "                results = list(results) + [0 for i in range(29)]\n",
    "            results = reorder_labels_for_submission(results)\n",
    "            data_rows.append([audio_filename] + results)\n",
    "#             print([audio_filename] + results)\n",
    "    writer.writerows(data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a command similar to this on the command line to get results\n",
    "!python evaluate_predictions.py results_2019-5-6-aug.csv \"D:\\DCASE_2019\\annotations.csv\" \"D:\\DCASE_2019\\dcase-ust-taxonomy.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python extract_embedding.py \"D:\\DCASE_2019\\annotations.csv\" $SONYC_UST_PATH/data $SONYC_UST_PATH/features $SONYC_UST_PATH/vggish"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
